# ilab dataset

metadata:
    data_dir: '${oc.env:DATASET_LOCATION, ./data}/MVI数据/ROI_224'
    # parser is used to parse the dataset directory
    # each key-value pair will be a field in the DataFrame
    parser:
        image: "lambda path: path.endswith('.jpg')"  # `image` must be included
        label: "lambda path: int(os.path.basename(path).split('.')[0].split('_')[0][-1])"  # M0: 0, M1: 1, M2: 2
        patient_id: "lambda path: os.path.basename(path).split('.')[0].split('_')[0][:2]"
        model: "lambda path: os.path.basename(path).split('.')[0].split('_')[1]"
        number: "lambda path: os.path.basename(path).split('.')[0].split('_')[2]"
    group_by: ['label', 'patient_id', 'model']  # groupby op will stack the `image` with the same group
split:
    split_cols: ['patient_id']  # split by `patient_id` to avoid data leakage
    test_split_ratio: 0.1
    n_folds: 10
    shuffle: true
    seed: 42
    save_dir: "preprocess/roi224-no-patch-stack/split"
    save_name_dict:
        train: 'train_{0}.csv'  # {0} is a placeholder for fold number
        val: 'val_{0}.csv'
        test: 'test.csv'
    reset_split_index: True  # matters
    # indices are reset by order: train, val, test
    # it works by: `split_dataset_folds` by param `reset_split_index` in modules/monai_data_module.py
load:
    load_dir: "preprocess/roi224-no-patch-stack/split"
    load_name_dict:
        train: 'train_{0}.csv'  # {0} is a placeholder for fold number
        val: 'val_{0}.csv'
        test: 'test.csv'
    fold: 0
    dataset: 'Dataset'
    dataset_params:
    transform:
        LoadImaged:
            keys: ['image']
        StackImaged:
            keys: ['image']
        DropSliced:
            key: 'image'
            slice_idx: 1  # create a new key 'image_slice' with the slice index
        ToTensord:
            keys: ['image', 'image_slice']
        ScaleIntensityd:
            keys: ['image', 'image_slice']
            minv: 0.0
            maxv: 1.0
loader:
    train_loader:
        shuffle: False
        batch_size: 32
        num_workers: 4
        pin_memory: true
        persistent_workers: true
    val_loader:
        shuffle: False
        num_workers: 4
        batch_size: 32
    test_loader:
        shuffle: False
        num_workers: 4
        batch_size: 32


#  Normalize:
#    mean: [0.485, 0.456, 0.406]
#    std: [0.229, 0.224, 0.225]